# Tropy API examples

*Prototype Python module for Tropy's REST API and sample Jupyter notebook experiments including computer vision and multimodal large language models*

 - [Python module](https://github.com/stakats/tropy-api-examples/blob/master/tropy.py)
 - [Basic explorer for learning Tropy API functions](https://github.com/stakats/tropy-api-examples/blob/master/API%20Explorer.ipynb)
 - [Facial recognition of Tropy item photos](https://github.com/stakats/tropy-api-examples/blob/master/Facial%20Recognition.ipynb)
 - [Automated captioning and tagging of Tropy item photos](https://github.com/stakats/tropy-api-examples/blob/master/MMLLM%20Experiments.ipynb)

## Description

This repository includes experimental code for reading and writing Tropy data, and linking Tropy to external services including
computer vision and generative AI.

Tropy is free, open-source software that allows you to organize and describe photographs of research material. Once you have imported 
your photos into Tropy, you can combine photos into items (e.g., photos of the three pages of a letter into a single item), and group 
photos into lists. You can also describe the content of a photograph. Tropy uses customizable metadata templates with multiple fields 
for different properties of the content of your photo, for example, title, date, author, box, folder, collection, archive. You can 
enter information in the template for an individual photo or select multiple photos and add or edit information to them in bulk. Tropy 
also lets you tag photos. You can also add one or more notes to a photo; a note could be a transcription of a document. A search 
function lets you find material in your photos, using metadata, tags, and notes.

## Development

### Requirements

Recommend a conda environment running Python 3.10 or later. 
